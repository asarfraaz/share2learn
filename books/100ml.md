---
layout: default
---

# The 100 Page Machine Learning Book

This is a short summary of my notes from this book


**Table of Contents**
* 
{:toc}

## Book Reading Details

|Tag|Information|Tag|Information|
|--:|--|--:|--|
| **Book Name**   | The 100 Page Machine Learning Book  | **Tagline**     | |
| **Author**      | Andriy Burkov                      | **Year**        | 2019                                |
| **Pages**       | 136                                 | **Chapters**    | 11                                  |
| **Start Date**  | 25-Sep-2023                         | **End Date**    |                                     |
| **Status** | In Progress | **Total Days**  | 20 days and counting ...           |

## Chapter 0 : Preface
- Machines don't learn !!!
- They only come up with a mathematical function that maps a set of inputs
  to a set of outputs
- If input values are from a different distribution than what the machine
  was trained on, then it would not give the right output. This is why it
  is not like the learning that we humans do
- "Machine Learning" is only a marketing term coined by Arthur Samuel in 1959
  while at IBM
- The term "Learning" in "Machine Learning" is only used as an analogy and not
  literally to mean the learning than we humans do

## Chapter 1 : Introduction

- Types of Learning
    1. Supervised Learning
        1.1 Creates a model using labelled examples ( or target is known )
        1.2 Commonly used for Predictions and Classification problems
    2. Semi-supervised Learning
        2.1 Contains a large number of unlabelled examples and a small number
        of labelled examples
        2.2 Saves costs for labelling a large dataset.
    3. Unsupervised Learning
        3.1 Creates a model using unlabelled examples
        3.2 Converts input data into another vector or a value that is later on
        used to solve a practical problem
    4. Reinforcement Learning
        4.1 Creates a policy ( a function similar to a model ) that outputs an
        action to execute for the give "state" the machine is in
        4.2 This is not covered in this book

- Support Vector Machine (SVM) algorithm is introduced to explain how
  Supervised Learning works

## Chapter 2 : Notation and Definitions

- Lots of mathematical concepts are defined and their intuition is explained
    1. Matrix
    2. Vector Operations
    3. Functions
    4. Derivative
    5. Random Variable
    6. Parameters
    7. Hyperparameters

- Classification algorithms predict the target class ( label )
- Regression algorithms predict a real-valued label
- Model-Based Learning is about learning the optimum "parameters" for a model
- Instance-Based Learning is about using the entire dataset as a model. Ex: KNN
- Shallow Learning is where the model parameters are learnt directly from the
  features of the training example
- Deep Learning is where most of the model parameters are learnt from the
  outputs of the preceding layers ( as in a deep neural network )

## Chapter 3 : Fundamental Algorithms

## Chapter 4 : Anatomy of a Learning Algorithm

## Chapter 5 : Best Practice

## Chapter 6 : Neural Networks and Deep Learning

## Chapter 7 : Problems and Solutions

## Chapter 8 : Advanced Practice

## Chapter 9 : Unsupervised Learning

## Chapter 10: Other Forms of Learning

## Chapter 11: Conclusion
